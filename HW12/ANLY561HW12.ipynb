{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANLY561 Homework 12\n",
    "# Hongyang Zheng\n",
    "\n",
    "<br>\n",
    "### Question1\n",
    "###### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare and define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "\n",
    "def chain_rule(Dg, Df, var_shape):\n",
    "    dim = len(var_shape)\n",
    "    Dg_axes = list(range(Dg.ndim - dim, Dg.ndim))\n",
    "    Df_axes = list(range(dim))\n",
    "    return np.tensordot(Dg, Df, axes=(Dg_axes, Df_axes))\n",
    "\n",
    "\n",
    "def DX_affine(X, W, b):\n",
    "    D = np.zeros((X.shape[0], W.shape[1], X.shape[0], X.shape[1]))\n",
    "    for k in range(X.shape[0]):\n",
    "        D[k,:,k,:] = W.T\n",
    "    return D, X.shape\n",
    "\n",
    "\n",
    "def DW_affine(X, W, b):\n",
    "    D = np.zeros((X.shape[0], W.shape[1], W.shape[0], W.shape[1]))\n",
    "    for k in range(W.shape[1]):\n",
    "        D[:,k,:,k] = X\n",
    "    return D, W.shape\n",
    "\n",
    "\n",
    "def Db_affine(X, W, b):\n",
    "    D = np.zeros((X.shape[0], W.shape[1], b.shape[1]))\n",
    "    for k in range(b.shape[1]):\n",
    "        D[:,k,k] = 1\n",
    "    return D, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi3(X, var):\n",
    "    return matrix_softmax(\n",
    "        logit(logit(X @ var[0] + var[1])@ var[2] + var[3])@ var[4] + var[5])\n",
    "\n",
    "    \n",
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def Dlogit(Z):\n",
    "    D = np.zeros((Z.shape[0], Z.shape[1], Z.shape[0], Z.shape[1]))\n",
    "    A = logit(Z) * logit(-Z)\n",
    "    for i in range(Z.shape[0]):\n",
    "        for j in range(Z.shape[1]):\n",
    "            D[i,j,i,j] = A[i,j]\n",
    "    return D, Z.shape\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "    v = np.exp(z)\n",
    "    return v / np.sum(v)\n",
    "\n",
    "\n",
    "def matrix_softmax(Z):\n",
    "    return np.apply_along_axis(softmax, 1, Z)\n",
    "\n",
    "\n",
    "def Dmatrix_softmax(Z):\n",
    "    D = np.zeros((Z.shape[0], Z.shape[1], Z.shape[0], Z.shape[1]))\n",
    "    for k in range(Z.shape[0]):\n",
    "        v = np.exp(Z[k,:])\n",
    "        v = v / np.sum(v)\n",
    "        D[k,:,k,:] = np.diag(v) - np.outer(v, v)\n",
    "    return D, Z.shape\n",
    "\n",
    "\n",
    "def cross_entropy(P, Q):\n",
    "    return -np.sum(P * np.log(Q)) / P.shape[0]\n",
    "\n",
    "\n",
    "def DQcross_entropy(P, Q):\n",
    "    return - P * (1 / Q) / P.shape[0], Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_loss_closure(X, Y):\n",
    "    f = lambda var: cross_entropy(Y, psi3(X, var))\n",
    "    return f\n",
    "\n",
    "\n",
    "def nn_loss_gradient_closure(X, Y):\n",
    "    def df(var):\n",
    "        # 1st hidden layer\n",
    "        Z1 = (X @ var[0]) + var[1]\n",
    "        X2 = logit(Z1)\n",
    "        \n",
    "        # 2nd hidden layer\n",
    "        Z2 = (X2 @ var[2]) + var[3]\n",
    "        X3 = logit(Z2)\n",
    "        \n",
    "        # output layer\n",
    "        Z3 = (X3 @ var[4]) + var[5]\n",
    "        Q = matrix_softmax(Z3)\n",
    "        \n",
    "        D_Q, Qshape = DQcross_entropy(Y, Q)\n",
    "        D_Z3, Z3shape = Dmatrix_softmax(Z3)\n",
    "        back_prop3 = chain_rule(D_Q, D_Z3, Qshape)\n",
    "        \n",
    "        D_X3, X3shape = DX_affine(X3, var[4], var[5])\n",
    "        D_W3, W3shape = DW_affine(X3, var[4], var[5])\n",
    "        D_b3, b3shape = Db_affine(X3, var[4], var[5])\n",
    "        \n",
    "        D_Z2, Z2shape = Dlogit(Z2)\n",
    "        back_prop2 = chain_rule(\n",
    "            chain_rule(back_prop3, D_X3, X3shape),\n",
    "            D_Z2, \n",
    "            Z2shape\n",
    "        )\n",
    "        \n",
    "        D_X2, X2shape = DX_affine(X2, var[2], var[3])\n",
    "        D_W2, W2shape = DW_affine(X2, var[2], var[3])\n",
    "        D_b2, b2shape = Db_affine(X2, var[2], var[3])\n",
    "        \n",
    "        D_Z1, Z1shape = Dlogit(Z1)\n",
    "        back_prop1 = chain_rule(\n",
    "            chain_rule(back_prop2, D_X2, X2shape), \n",
    "            D_Z1, \n",
    "            Z1shape\n",
    "        )\n",
    "        \n",
    "        D_W1, W1shape = DW_affine(X, var[0], var[1])\n",
    "        D_b1, b1shape = Db_affine(X, var[0], var[1])\n",
    "        \n",
    "        W1grad = chain_rule(back_prop1, D_W1, W1shape)\n",
    "        b1grad = chain_rule(back_prop1, D_b1, b1shape)\n",
    "        W2grad = chain_rule(back_prop2, D_W2, W2shape)\n",
    "        b2grad = chain_rule(back_prop2, D_b2, b2shape)\n",
    "        W3grad = chain_rule(back_prop3, D_W3, W3shape)\n",
    "        b3grad = chain_rule(back_prop3, D_b3, b3shape)\n",
    "        \n",
    "        return [W1grad, b1grad, W2grad, b2grad, W3grad, b3grad]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_blocks(x, y, t):\n",
    "    num_blocks = len(x)\n",
    "    z = [None] * num_blocks\n",
    "    for i in range(num_blocks):\n",
    "        z[i] = x[i] + t * y[i]\n",
    "    return z\n",
    "      \n",
    "    \n",
    "def block_backtracking(x0, f, dx, df0, alpha=0.1, beta=0.5):\n",
    "    num_blocks = len(x0)\n",
    "    \n",
    "    delta = 0\n",
    "    for i in range(num_blocks):\n",
    "        delta = delta + np.sum(dx[i] * df0[i])\n",
    "    delta = alpha * delta\n",
    "    \n",
    "    f0 = f(x0)\n",
    "    \n",
    "    t = 1\n",
    "    x = update_blocks(x0, dx, t)\n",
    "    fx = f(x)\n",
    "    while (not np.isfinite(fx)) or f0 + t * delta < fx:\n",
    "        t = beta * t\n",
    "        x = update_blocks(x0, dx, t)\n",
    "        fx = f(x)\n",
    "        \n",
    "    return x, fx\n",
    "\n",
    "\n",
    "def negate_blocks(x):\n",
    "    num_blocks = len(x)\n",
    "    z = [None] * num_blocks\n",
    "    for i in range(num_blocks):\n",
    "        z[i] = -x[i]\n",
    "    return z\n",
    "\n",
    "\n",
    "def block_norm(x):\n",
    "    num_blocks=len(x)\n",
    "    z = 0\n",
    "    for i in range(num_blocks):\n",
    "        z = z + np.sum(x[i] ** 2)\n",
    "    return np.sqrt(z)\n",
    "\n",
    "\n",
    "def random_matrix(shape, sigma=0.1):\n",
    "    return np.reshape(sigma * rd.randn(shape[0] * shape[1]), shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the dataset \n",
    "data = load_breast_cancer()\n",
    "\n",
    "dim_data = 30\n",
    "num_labels = 2\n",
    "num_examples = 569\n",
    "\n",
    "num_train = 400\n",
    "\n",
    "X = data['data'] \n",
    "targets = data.target \n",
    "labels = np.zeros((num_examples, num_labels))\n",
    "for i in range(num_examples):\n",
    "    labels[i, targets[i]] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "rd.seed(1234)\n",
    "\n",
    "# Prepare hyperparameters of the network\n",
    "hidden_nodes = 20\n",
    "\n",
    "# Initialize variables\n",
    "W1_init = random_matrix((dim_data, hidden_nodes))\n",
    "b1_init = np.zeros((1, hidden_nodes))\n",
    "\n",
    "W2_init = random_matrix((hidden_nodes, hidden_nodes))\n",
    "b2_init = np.zeros((1, hidden_nodes))\n",
    "\n",
    "W3_init = random_matrix((hidden_nodes, num_labels))\n",
    "b3_init = np.zeros((1, num_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 steps of gradient descent with block backtracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0,  Mean loss: 0.684698,  Gradient norm: 0.573653,  Accuracy: 56.8\n",
      "Step: 10,  Mean loss: 0.683966,  Gradient norm: 0.001043,  Accuracy: 56.8\n",
      "Step: 20,  Mean loss: 0.683963,  Gradient norm: 0.000943,  Accuracy: 56.8\n",
      "Step: 30,  Mean loss: 0.683961,  Gradient norm: 0.001235,  Accuracy: 56.8\n",
      "Step: 40,  Mean loss: 0.683958,  Gradient norm: 0.000846,  Accuracy: 56.8\n",
      "Step: 50,  Mean loss: 0.683956,  Gradient norm: 0.001086,  Accuracy: 56.8\n",
      "Step: 60,  Mean loss: 0.683953,  Gradient norm: 0.001297,  Accuracy: 56.8\n",
      "Step: 70,  Mean loss: 0.683951,  Gradient norm: 0.001118,  Accuracy: 56.8\n",
      "Step: 80,  Mean loss: 0.683948,  Gradient norm: 0.001184,  Accuracy: 56.8\n",
      "Step: 90,  Mean loss: 0.683946,  Gradient norm: 0.001647,  Accuracy: 56.8\n",
      "Final test accuracy: 76.9 percent\n"
     ]
    }
   ],
   "source": [
    "x = [W1_init, b1_init, W2_init, b2_init, W3_init, b3_init]\n",
    "f = nn_loss_closure(X[:num_train], labels[:num_train])\n",
    "df = nn_loss_gradient_closure(X[:num_train], labels[:num_train])\n",
    "dx = lambda v: negate_blocks(df(v))\n",
    "    \n",
    "for i in range(100):\n",
    "    ngrad = dx(x)\n",
    "    x, fval = block_backtracking(x, f, ngrad, df(x), alpha=0.1)\n",
    "    \n",
    "    train_data = psi3(X[:num_train], x)\n",
    "    train_labels = np.argmax(train_data, axis=1)\n",
    "    per_correct = 100 * (1 - np.count_nonzero(\n",
    "        train_labels - targets[:num_train]) / num_train)\n",
    "\n",
    "    if ((i % 10) == 0):\n",
    "        print(\n",
    "            \"Step: {:2d}, \".format(i),\n",
    "            \"Mean loss: {:.6f}, \".format(fval),\n",
    "            \"Gradient norm: {:.6f}, \".format(block_norm(ngrad)),\n",
    "            \"Accuracy: {:.1f}\".format(per_correct)\n",
    "        )\n",
    "    \n",
    "test_data = psi3(X[num_train:], x)\n",
    "\n",
    "test_labels = np.argmax(test_data, axis=1)\n",
    "per_correct = 100 * (1 - np.count_nonzero(\n",
    "    test_labels - targets[num_train:]) / (num_examples - num_train))\n",
    "\n",
    "print('Final test accuracy: %.1f percent' % per_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### b)\n",
    "1. We can reduce the size of the training set: for example, including fewer observations/rows or fewer attributes/columns.\n",
    "2. We can simplify network architecture: for example, reducing the number of nodes in the network. \n",
    "3. We can use stochastic gradient descent, because it uses less memory and time than gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### a)\n",
    "Assume $\\mathcal{A}$ is the forth order tensor and $\\mathbf{n}=\\left(2,2,3,3\\right)$\n",
    "\n",
    "Calculate the convolution of X, then we have:\n",
    "\n",
    "$$\n",
    "\\mathbf{X}\\ast\n",
    "\\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "x_{1,1} & x_{1,2} & x_{1,3} \\\\\n",
    "x_{2,1} & x_{2,2} & x_{2,3} \\\\\n",
    "x_{3,1} & x_{3,2} & x_{3,3}\n",
    "\\end{pmatrix}\n",
    "\\ast\n",
    "\\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "x_{1,1}+x_{2,2} & x_{1,2}+x_{2,3} \\\\\n",
    "x_{2,1}+x_{3,2} & x_{2,2}+x_{3,3}\n",
    "\\end{pmatrix},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, it is a $2\\times 2$ matrix.\n",
    "\n",
    "Denote this matrix as $\\mathcal{F}$ and $\\mathbf{m}=\\left(3,3\\right)$, then we have:\n",
    "\n",
    "$$\n",
    "c_{\\mathbf{i},\\mathbf{j}}:\\mathscr{F}_{\\mathbf{n}}\\times\\mathscr{F}_{\\mathbf{m}}\\rightarrow\\mathscr{F}_{\\mathbf{n}_{\\setminus\\mathbf{i}}\\oplus\\mathbf{m}_{\\setminus\\mathbf{j}}}=\\mathscr{F}_{\\left(2,2\\right)}.\n",
    "$$\n",
    "\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$\n",
    "f_{i_{1},i_{2}}=\\sum_{k_{1}=1}^{3}\\sum_{k_{2}=1}^{3}a_{i_{1},i_{2},k_{1},k_{2}}x_{k_{1},k_{2}}.\n",
    "$$\n",
    "\n",
    "Then we have:\n",
    "$$\n",
    "\\begin{align*}\n",
    "f_{1,1} & = x_{1,1}+x_{2,2}\\implies a_{1,1,k_{1},k_{2}}=\n",
    "\\begin{cases}\n",
    "1, & \\left(k_{1},k_{2}\\right)\\in\\left\\{\\left(1,1\\right),\\left(2,2\\right)\\right\\} \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases} \\\\\n",
    "f_{1,2} & = x_{1,2}+x_{2,3}\\implies a_{1,2,k_{1},k_{2}}=\n",
    "\\begin{cases}\n",
    "1, & \\left(k_{1},k_{2}\\right)\\in\\left\\{\\left(1,2\\right),\\left(2,3\\right)\\right\\} \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases} \\\\\n",
    "f_{2,1} & = x_{2,1}+x_{3,2}\\implies a_{2,1,k_{1},k_{2}}=\n",
    "\\begin{cases}\n",
    "1, & \\left(k_{1},k_{2}\\right)\\in\\left\\{\\left(2,1\\right),\\left(3,2\\right)\\right\\} \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases} \\\\\n",
    "f_{2,2} & = x_{2,2}+x_{3,3}\\implies a_{2,2,k_{1},k_{2}}=\n",
    "\\begin{cases}\n",
    "1, & \\left(k_{1},k_{2}\\right)\\in\\left\\{\\left(2,2\\right),\\left(3,3\\right)\\right\\} \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Therefore, the fourth order tensor is\n",
    "\n",
    "$$\n",
    "\\mathcal{A}=\n",
    "\\left(\n",
    "\\left(\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 0\n",
    "\\end{pmatrix},\n",
    "\\begin{pmatrix}\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1 \\\\\n",
    "0 & 0 & 0\n",
    "\\end{pmatrix}\n",
    "\\right),\n",
    "\\left(\n",
    "\\begin{pmatrix}\n",
    "0 & 0 & 0 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0\n",
    "\\end{pmatrix},\n",
    "\\begin{pmatrix}\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\right)\n",
    "\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### b)\n",
    "Assume $\\mathcal{A}$ is the fifth order tensor and $\\mathbf{n}=\\left(2,2,2,3,3\\right)$\n",
    "\n",
    "Calculate the convolution of X, then we have:\n",
    "$$\n",
    "\\begin{align*}\n",
    "& \\left(\n",
    "\\begin{pmatrix}\n",
    "x_{1,1,1} & x_{1,1,2} & x_{1,1,3} \\\\\n",
    "x_{1,2,1} & x_{1,2,2} & x_{1,2,3} \\\\\n",
    "x_{1,3,1} & x_{1,3,2} & x_{1,3,3}\n",
    "\\end{pmatrix},\n",
    "\\begin{pmatrix}\n",
    "x_{2,1,1} & x_{2,1,2} & x_{2,1,3} \\\\\n",
    "x_{2,2,1} & x_{2,2,2} & x_{2,2,3} \\\\\n",
    "x_{2,3,1} & x_{2,3,2} & x_{2,3,3}\n",
    "\\end{pmatrix}\n",
    "\\right)\n",
    "\\ast\n",
    "\\left(\n",
    "\\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{pmatrix},\n",
    "\\begin{pmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & 1\n",
    "\\end{pmatrix}\n",
    "\\right) \\\\\n",
    "& = \n",
    "\\begin{pmatrix}\n",
    "x_{1,1,1} & x_{1,1,2} & x_{1,1,3} \\\\\n",
    "x_{1,2,1} & x_{1,2,2} & x_{1,2,3} \\\\\n",
    "x_{1,3,1} & x_{1,3,2} & x_{1,3,3}\n",
    "\\end{pmatrix}\n",
    "\\ast\n",
    "\\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{pmatrix}\n",
    "+\n",
    "\\begin{pmatrix}\n",
    "x_{2,1,1} & x_{2,1,2} & x_{2,1,3} \\\\\n",
    "x_{2,2,1} & x_{2,2,2} & x_{2,2,3} \\\\\n",
    "x_{2,3,1} & x_{2,3,2} & x_{2,3,3}\n",
    "\\end{pmatrix}\n",
    "\\ast\n",
    "\\begin{pmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & 1\n",
    "\\end{pmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "From part a), we know that the first part is:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "x_{1,1,1} + x_{1,2,2} & x_{1,1,2} + x_{1,2,3} \\\\\n",
    "x_{1,2,1} + x_{1,3,2} & x_{1,2,2} + x_{1,3,3}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Therefore, the result is:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "x_{1,1,1} + x_{1,2,2} + x_{2,1,1} + x_{2,1,2} + x_{2,2,1} + x_{2,2,2} &\n",
    "x_{1,1,2} + x_{1,2,3} + x_{2,1,2} + x_{2,1,3} + x_{2,2,2} + x_{2,2,3} \\\\\n",
    "x_{1,2,1} + x_{1,3,2} + x_{2,2,1} + x_{2,2,2} + x_{2,3,1} + x_{2,3,2} & \n",
    "x_{1,2,2} + x_{1,3,3} + x_{2,2,2} + x_{2,2,3} + x_{2,3,2} + x_{2,3,3}\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "Therefore, it is a $2\\times 2$ matrix.\n",
    "\n",
    "Denote this matrix as $\\mathcal{F}$ and $\\mathbf{m}=\\left(2,3,3\\right)$, then we have:\n",
    "$$\n",
    "c_{\\mathbf{i},\\mathbf{j}}:\\mathscr{F}_{\\mathbf{n}}\\times\\mathscr{F}_{\\mathbf{m}}\\rightarrow\\mathscr{F}_{\\mathbf{n}_{\\setminus\\mathbf{i}}\\oplus\\mathbf{m}_{\\setminus\\mathbf{j}}}=\\mathscr{F}_{\\left(2,2\\right)}.\n",
    "$$\n",
    "\n",
    "And $\\mathcal{F}=$\n",
    "$$\n",
    "f_{i_{1},i_{2}}=\\sum_{k_{1}=1}^{2}\\sum_{k_{2}=1}^{3}\\sum_{k_{3}=1}^{3}a_{i_{1},i_{2},k_{1},k_{2},k_{3}}x_{k_{1},k_{2},k_{3}}.\n",
    "$$\n",
    "\n",
    "We know $$\n",
    "f_{1,1} = \\sum_{k_{1}=1}^{2}\\sum_{k_{2}=1}^{3}\\sum_{k_{3}=1}^{3}a_{1,1,k_{1},k_{2},k_{3}}x_{k_{1},k_{2},k_{3}}= x_{1,1,1} + x_{1,2,2} + x_{2,1,1} + x_{2,1,2} + x_{2,2,1} + x_{2,2,2},\n",
    "$$\n",
    "\n",
    "Therefore:\n",
    "$$\n",
    "\\begin{align*}\n",
    "a_{1,1,k_{1},k_{2},k_{3}} & =\n",
    "\\begin{cases}\n",
    "1, & \\left(k_{1},k_{2},k_{3}\\right)\\in\\left\\{\n",
    "\\left(1,1,1\\right),\n",
    "\\left(1,2,2\\right),\n",
    "\\left(2,1,1\\right),\n",
    "\\left(2,1,2\\right),\n",
    "\\left(2,2,1\\right),\n",
    "\\left(2,2,2\\right)\n",
    "\\right\\} \\\\\n",
    "0 , & \\text{otherwise}\n",
    "\\end{cases} \\\\\n",
    "a_{1,2,k_{1},k_{2},k_{3}} & =\n",
    "\\begin{cases}\n",
    "1, & \\left(k_{1},k_{2},k_{3}\\right)\\in\\left\\{\n",
    "\\left(1,1,2\\right),\n",
    "\\left(1,2,3\\right),\n",
    "\\left(2,1,2\\right),\n",
    "\\left(2,1,3\\right),\n",
    "\\left(2,2,2\\right),\n",
    "\\left(2,2,3\\right)\n",
    "\\right\\} \\\\\n",
    "0 , & \\text{otherwise}\n",
    "\\end{cases} \\\\\n",
    "a_{2,1,k_{1},k_{2},k_{3}} & =\n",
    "\\begin{cases}\n",
    "1, & \\left(k_{1},k_{2},k_{3}\\right)\\in\\left\\{\n",
    "\\left(1,2,1\\right),\n",
    "\\left(1,3,2\\right),\n",
    "\\left(2,2,1\\right),\n",
    "\\left(2,2,2\\right),\n",
    "\\left(2,3,1\\right),\n",
    "\\left(2,3,2\\right)\n",
    "\\right\\} \\\\\n",
    "0 , & \\text{otherwise}\n",
    "\\end{cases} \\\\\n",
    "a_{2,2,k_{1},k_{2},k_{3}} & =\n",
    "\\begin{cases}\n",
    "1, & \\left(k_{1},k_{2},k_{3}\\right)\\in\\left\\{\n",
    "\\left(1,2,2\\right),\n",
    "\\left(1,3,3\\right),\n",
    "\\left(2,2,2\\right),\n",
    "\\left(2,2,3\\right),\n",
    "\\left(2,3,2\\right),\n",
    "\\left(2,3,3\\right)\n",
    "\\right\\} \\\\\n",
    "0 , & \\text{otherwise}\n",
    "\\end{cases}.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Thus, the fifth order tensor is\n",
    "\n",
    "$$\n",
    "\\mathcal{A} =\n",
    "\\left(\n",
    "  \\left(\n",
    "    \\left(\n",
    "      \\begin{pmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 0\n",
    "\\end{pmatrix}, \\begin{pmatrix}\n",
    "1 & 1 & 0 \\\\\n",
    "1 & 1 & 0 \\\\\n",
    "0 & 0 & 0\n",
    "\\end{pmatrix}\n",
    "    \\right),\n",
    "    \\left(\n",
    "      \\begin{pmatrix}\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1 \\\\\n",
    "0 & 0 & 0\n",
    "\\end{pmatrix}, \\begin{pmatrix}\n",
    "0 & 1 & 1 \\\\\n",
    "0 & 1 & 1 \\\\\n",
    "0 & 0 & 0\n",
    "\\end{pmatrix}\n",
    "    \\right)\n",
    "  \\right),  \n",
    "  \\left(\n",
    "    \\left(\n",
    "      \\begin{pmatrix}\n",
    "0 & 0 & 0 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0\n",
    "\\end{pmatrix}, \\begin{pmatrix}\n",
    "0 & 0 & 0 \\\\\n",
    "1 & 1 & 0 \\\\\n",
    "1 & 1 & 0\n",
    "\\end{pmatrix} \n",
    "    \\right),\n",
    "    \\left(\n",
    "      \\begin{pmatrix}\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{pmatrix}, \\begin{pmatrix}\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 1 & 1 \\\\\n",
    "0 & 1 & 1\n",
    "\\end{pmatrix}\n",
    "    \\right)\n",
    "  \\right)  \n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see the pdf document."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
